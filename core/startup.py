#!/usr/bin/env python3
"""
ç³»ç»Ÿå¯åŠ¨å™¨ - è‡ªåŠ¨æ‰«æå’Œé‡å»ºå‘é‡æ•°æ®åº“

åŠŸèƒ½ï¼š
1. å¯åŠ¨æ—¶è‡ªåŠ¨æ‰«æ /notes ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
2. æ£€æµ‹æ–‡ä»¶å˜åŒ–ï¼ˆæ–°å¢ã€åˆ é™¤ã€ä¿®æ”¹ï¼‰
3. æ™ºèƒ½é‡å»ºå‘é‡ï¼ˆåªå¤„ç†å˜åŒ–çš„æ–‡ä»¶ï¼‰
4. æ”¯æŒå¼ºåˆ¶å…¨é‡é‡å»º
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Set
import json
import hashlib

from text_analyzer import ChineseTextAnalyzer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VectorIndexManager:
    """å‘é‡ç´¢å¼•ç®¡ç†å™¨ - è´Ÿè´£å¯åŠ¨æ—¶çš„å‘é‡é‡å»º"""
    
    def __init__(self, 
                 notes_directory: str = None,
                 file_pattern: str = "*",  # æ”¹ä¸ºåŒ¹é…æ‰€æœ‰æ–‡ä»¶
                 collection_name: str = "smart_notes"):
        """
        åˆå§‹åŒ–å‘é‡ç´¢å¼•ç®¡ç†å™¨
        
        Args:
            notes_directory: notesç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º./notes
            file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œé»˜è®¤ä¸º"*"åŒ¹é…æ‰€æœ‰æ–‡ä»¶
            collection_name: Qdranté›†åˆåç§°
        """
        if notes_directory is None:
            # é»˜è®¤ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„notesæ–‡ä»¶å¤¹
            project_root = Path(__file__).parent.parent
            notes_directory = project_root / "notes"
        
        self.notes_directory = Path(notes_directory)
        self.file_pattern = file_pattern
        self.collection_name = collection_name
        
        # çŠ¶æ€æ–‡ä»¶ç”¨äºè®°å½•ä¸Šæ¬¡æ‰«æçš„æ–‡ä»¶çŠ¶æ€
        self.state_file = Path("vector_index_state.json")
        self.last_scan_state = self._load_scan_state()
        
        # åˆå§‹åŒ–æ–‡æœ¬åˆ†æå™¨
        self.analyzer = None
        
    def _load_scan_state(self) -> Dict[str, Any]:
        """åŠ è½½ä¸Šæ¬¡æ‰«æçŠ¶æ€"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                logger.info(f"åŠ è½½ä¸Šæ¬¡æ‰«æçŠ¶æ€ï¼ŒåŒ…å« {len(state.get('files', {}))} ä¸ªæ–‡ä»¶è®°å½•")
                return state
            except Exception as e:
                logger.warning(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        return {"files": {}, "last_scan": None}
    
    def _save_scan_state(self, current_state: Dict[str, Any]):
        """ä¿å­˜å½“å‰æ‰«æçŠ¶æ€"""
        try:
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(current_state, f, ensure_ascii=False, indent=2)
            logger.info(f"ä¿å­˜æ‰«æçŠ¶æ€ï¼ŒåŒ…å« {len(current_state.get('files', {}))} ä¸ªæ–‡ä»¶è®°å½•")
        except Exception as e:
            logger.error(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
    
    def _get_file_metadata(self, file_path: Path) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶å…ƒæ•°æ®"""
        try:
            stat = file_path.stat()
            return {
                "size": stat.st_size,
                "mtime": stat.st_mtime,
                "path": str(file_path)
            }
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹å“ˆå¸Œ"""
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
            return hashlib.md5(content).hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    def scan_notes_directory(self) -> Dict[str, Any]:
        """æ‰«ænotesç›®å½•ï¼Œæ£€æµ‹æ–‡ä»¶å˜åŒ–"""
        if not self.notes_directory.exists():
            logger.error(f"Notesç›®å½•ä¸å­˜åœ¨: {self.notes_directory}")
            return {"added": [], "modified": [], "deleted": [], "unchanged": []}
        
        logger.info(f"å¼€å§‹æ‰«æç›®å½•: {self.notes_directory}")
        
        # è·å–å½“å‰æ‰€æœ‰æ–‡ä»¶ï¼ˆæ’é™¤éšè—æ–‡ä»¶å’Œç³»ç»Ÿæ–‡ä»¶ï¼‰
        current_files = {}
        all_files = list(self.notes_directory.glob(self.file_pattern))
        
        # è¿‡æ»¤æ‰éšè—æ–‡ä»¶å’Œç³»ç»Ÿæ–‡ä»¶
        txt_files = [f for f in all_files if not f.name.startswith('.') and not f.name.startswith('~')]
        
        for file_path in txt_files:
            file_key = str(file_path)
            metadata = self._get_file_metadata(file_path)
            if metadata:
                metadata["hash"] = self._calculate_file_hash(file_path)
                current_files[file_key] = metadata
        
        # æ¯”è¾ƒæ–‡ä»¶å˜åŒ–
        last_files = self.last_scan_state.get("files", {})
        
        added_files = []
        modified_files = []
        deleted_files = []
        unchanged_files = []
        
        # æ£€æŸ¥æ–°å¢å’Œä¿®æ”¹çš„æ–‡ä»¶
        for file_key, current_meta in current_files.items():
            if file_key not in last_files:
                # æ–°å¢æ–‡ä»¶
                added_files.append(file_key)
                logger.info(f"æ–°å¢æ–‡ä»¶: {Path(file_key).name}")
            else:
                last_meta = last_files[file_key]
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«ä¿®æ”¹ï¼ˆé€šè¿‡å¤§å°ã€ä¿®æ”¹æ—¶é—´å’Œå“ˆå¸Œå€¼ï¼‰
                if (current_meta.get("size") != last_meta.get("size") or 
                    current_meta.get("mtime") != last_meta.get("mtime") or
                    current_meta.get("hash") != last_meta.get("hash")):
                    # æ–‡ä»¶è¢«ä¿®æ”¹
                    modified_files.append(file_key)
                    logger.info(f"ä¿®æ”¹æ–‡ä»¶: {Path(file_key).name}")
                else:
                    # æ–‡ä»¶æœªå˜åŒ–
                    unchanged_files.append(file_key)
        
        # æ£€æŸ¥åˆ é™¤çš„æ–‡ä»¶
        for file_key in last_files:
            if file_key not in current_files:
                deleted_files.append(file_key)
                logger.info(f"åˆ é™¤æ–‡ä»¶: {Path(file_key).name}")
        
        # æ›´æ–°æ‰«æçŠ¶æ€
        new_state = {
            "files": current_files,
            "last_scan": datetime.now().isoformat(),
            "total_files": len(current_files)
        }
        self._save_scan_state(new_state)
        self.last_scan_state = new_state
        
        result = {
            "added": added_files,
            "modified": modified_files,
            "deleted": deleted_files,
            "unchanged": unchanged_files,
            "total_current": len(current_files),
            "scan_time": new_state["last_scan"]
        }
        
        logger.info(f"æ‰«æå®Œæˆ - æ–°å¢: {len(added_files)}, ä¿®æ”¹: {len(modified_files)}, "
                   f"åˆ é™¤: {len(deleted_files)}, æœªå˜åŒ–: {len(unchanged_files)}")
        
        return result
    
    def init_analyzer(self) -> bool:
        """åˆå§‹åŒ–æ–‡æœ¬åˆ†æå™¨"""
        try:
            self.analyzer = ChineseTextAnalyzer(
                model_name="quentinz/bge-large-zh-v1.5",
                use_ollama=True,
                qdrant_host="localhost",
                qdrant_port=6333,
                collection_name=self.collection_name
            )
            logger.info("æ–‡æœ¬åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ–‡æœ¬åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def rebuild_vectors(self, force_full_rebuild: bool = False) -> Dict[str, Any]:
        """é‡å»ºå‘é‡ç´¢å¼•"""
        if not self.analyzer:
            if not self.init_analyzer():
                return {"success": False, "error": "æ–‡æœ¬åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥"}
        
        start_time = datetime.now()
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹å‘é‡ç´¢å¼•é‡å»º")
        logger.info("=" * 60)
        
        try:
            # æ‰«æç›®å½•å˜åŒ–
            scan_result = self.scan_notes_directory()
            
            if force_full_rebuild:
                logger.info("ğŸ”„ å¼ºåˆ¶å…¨é‡é‡å»ºæ¨¡å¼")
                # æ¸…ç©ºç°æœ‰çš„å‘é‡æ•°æ®
                self._clear_vector_collection()
                
                # é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶
                all_files = scan_result["added"] + scan_result["modified"] + scan_result["unchanged"]
                if all_files:
                    success = self.analyzer.process_directory(
                        str(self.notes_directory), 
                        force_refresh=True
                    )
                else:
                    logger.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶éœ€è¦å¤„ç†")
                    success = True
                
                processed_files = all_files
                
            else:
                logger.info("ğŸ¯ æ™ºèƒ½å¢é‡é‡å»ºæ¨¡å¼")
                
                # å¤„ç†åˆ é™¤çš„æ–‡ä»¶
                for deleted_file in scan_result["deleted"]:
                    self._remove_file_from_vectors(deleted_file)
                
                # å¤„ç†æ–°å¢å’Œä¿®æ”¹çš„æ–‡ä»¶
                files_to_process = scan_result["added"] + scan_result["modified"]
                
                if files_to_process:
                    logger.info(f"éœ€è¦å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶")
                    
                    # å¯¹äºä¿®æ”¹çš„æ–‡ä»¶ï¼Œå…ˆåˆ é™¤æ—§çš„å‘é‡
                    for modified_file in scan_result["modified"]:
                        self._remove_file_from_vectors(modified_file)
                    
                    # å¤„ç†æ–‡ä»¶
                    success = self.analyzer.process_directory(
                        str(self.notes_directory),
                        force_refresh=False
                    )
                else:
                    logger.info("æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯æœ€æ–°çš„ï¼Œæ— éœ€å¤„ç†")
                    success = True
                
                processed_files = files_to_process
            
            # è·å–æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
            if success:
                stats = self.analyzer.get_collection_stats()
                cache_info = self.analyzer.get_cache_info()
                
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                
                result = {
                    "success": True,
                    "scan_result": scan_result,
                    "processed_files_count": len(processed_files),
                    "total_vectors": stats.get("total_points", 0),
                    "vector_dimension": stats.get("vector_size", 0),
                    "cached_files": cache_info.get("total_cached_files", 0),
                    "duration_seconds": round(duration, 2),
                    "rebuild_type": "full" if force_full_rebuild else "incremental",
                    "timestamp": end_time.isoformat()
                }
                
                logger.info("=" * 60)
                logger.info("âœ… å‘é‡ç´¢å¼•é‡å»ºå®Œæˆ")
                logger.info(f"ğŸ“Š å¤„ç†æ–‡ä»¶: {len(processed_files)}")
                logger.info(f"ğŸ“Š æ€»å‘é‡æ•°: {result['total_vectors']}")
                logger.info(f"ğŸ“Š å‘é‡ç»´åº¦: {result['vector_dimension']}")
                logger.info(f"â±ï¸  è€—æ—¶: {result['duration_seconds']} ç§’")
                logger.info("=" * 60)
                
                return result
            else:
                return {
                    "success": False,
                    "error": "å‘é‡å¤„ç†å¤±è´¥",
                    "scan_result": scan_result
                }
                
        except Exception as e:
            logger.error(f"å‘é‡é‡å»ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {
                "success": False,
                "error": str(e),
                "traceback": str(e)
            }
    
    def _clear_vector_collection(self):
        """æ¸…ç©ºå‘é‡é›†åˆ"""
        try:
            # åˆ é™¤å¹¶é‡æ–°åˆ›å»ºé›†åˆ
            collections = self.analyzer.qdrant_client.get_collections().collections
            collection_names = [c.name for c in collections]
            
            if self.collection_name in collection_names:
                self.analyzer.qdrant_client.delete_collection(self.collection_name)
                logger.info(f"åˆ é™¤ç°æœ‰é›†åˆ: {self.collection_name}")
            
            # é‡æ–°åˆ›å»ºé›†åˆ
            self.analyzer._create_collection_if_not_exists()
            logger.info(f"é‡æ–°åˆ›å»ºé›†åˆ: {self.collection_name}")
            
        except Exception as e:
            logger.error(f"æ¸…ç©ºå‘é‡é›†åˆå¤±è´¥: {e}")
    
    def _remove_file_from_vectors(self, file_path: str):
        """ä»å‘é‡åº“ä¸­åˆ é™¤æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰å‘é‡"""
        try:
            filename = Path(file_path).name
            
            # ä½¿ç”¨Qdrantçš„åˆ é™¤åŠŸèƒ½
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            
            delete_filter = Filter(
                must=[
                    FieldCondition(
                        key="filename",
                        match=MatchValue(value=filename)
                    )
                ]
            )
            
            result = self.analyzer.qdrant_client.delete(
                collection_name=self.collection_name,
                points_selector=delete_filter
            )
            
            logger.info(f"å·²åˆ é™¤æ–‡ä»¶ {filename} çš„å‘é‡æ•°æ®")
            
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ä»¶å‘é‡å¤±è´¥ {file_path}: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            status = {
                "notes_directory": str(self.notes_directory),
                "notes_directory_exists": self.notes_directory.exists(),
                "analyzer_initialized": self.analyzer is not None,
                "last_scan": self.last_scan_state.get("last_scan", "Never"),
                "total_files_tracked": len(self.last_scan_state.get("files", {})),
                "state_file_exists": self.state_file.exists()
            }
            
            if self.analyzer:
                try:
                    stats = self.analyzer.get_collection_stats()
                    cache_info = self.analyzer.get_cache_info()
                    
                    status.update({
                        "vector_stats": stats,
                        "cache_info": {
                            "total_cached_files": cache_info.get("total_cached_files", 0),
                            "cache_file_exists": cache_info.get("cache_exists", False)
                        }
                    })
                except Exception as e:
                    status["vector_stats_error"] = str(e)
            
            return status
            
        except Exception as e:
            return {"error": str(e)}


def startup_vector_rebuild(notes_directory: str = None,
                          force_full_rebuild: bool = False,
                          auto_mode: bool = False,
                          collection_name: str = "smart_notes") -> Dict[str, Any]:
    """
    å¯åŠ¨æ—¶å‘é‡é‡å»ºä¸»å‡½æ•°
    
    Args:
        notes_directory: notesç›®å½•è·¯å¾„
        force_full_rebuild: æ˜¯å¦å¼ºåˆ¶å…¨é‡é‡å»º
        auto_mode: è‡ªåŠ¨æ¨¡å¼ï¼ˆä¸éœ€è¦ç”¨æˆ·ç¡®è®¤ï¼‰
    """
    manager = VectorIndexManager(notes_directory)
    
    logger.info("ğŸ” æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
    status = manager.get_system_status()
    
    logger.info(f"ğŸ“ Notesç›®å½•: {status['notes_directory']}")
    logger.info(f"ğŸ“ ç›®å½•å­˜åœ¨: {'âœ…' if status['notes_directory_exists'] else 'âŒ'}")
    logger.info(f"ğŸ“ è·Ÿè¸ªæ–‡ä»¶æ•°: {status['total_files_tracked']}")
    logger.info(f"ğŸ• ä¸Šæ¬¡æ‰«æ: {status['last_scan']}")
    
    if not status['notes_directory_exists']:
        return {"success": False, "error": f"Notesç›®å½•ä¸å­˜åœ¨: {notes_directory}"}
    
    if not auto_mode:
        if force_full_rebuild:
            confirm = input("\nğŸ”„ ç¡®å®šè¦æ‰§è¡Œå¼ºåˆ¶å…¨é‡é‡å»ºå—ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰ç°æœ‰å‘é‡å¹¶é‡æ–°æ„å»º (y/N): ")
        else:
            confirm = input("\nğŸ¯ ç¡®å®šè¦æ‰§è¡Œæ™ºèƒ½å¢é‡é‡å»ºå—ï¼Ÿ (Y/n): ")
        
        if confirm.lower() not in ['y', 'yes', '']:
            return {"success": False, "error": "ç”¨æˆ·å–æ¶ˆæ“ä½œ"}
    
    # æ‰§è¡Œé‡å»º
    return manager.rebuild_vectors(force_full_rebuild)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å‘é‡ç´¢å¼•å¯åŠ¨é‡å»ºå·¥å…·")
    parser.add_argument("--notes-dir", 
                       default=None,
                       help="Notesç›®å½•è·¯å¾„")
    parser.add_argument("--force", 
                       action="store_true",
                       help="å¼ºåˆ¶å…¨é‡é‡å»º")
    parser.add_argument("--auto", 
                       action="store_true",
                       help="è‡ªåŠ¨æ¨¡å¼ï¼ˆæ— éœ€ç¡®è®¤ï¼‰")
    parser.add_argument("--status", 
                       action="store_true",
                       help="ä»…æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€")
    
    args = parser.parse_args()
    
    if args.status:
        # ä»…æ˜¾ç¤ºçŠ¶æ€
        manager = VectorIndexManager(args.notes_dir)
        status = manager.get_system_status()
        
        print("\n" + "=" * 50)
        print("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        print("=" * 50)
        
        for key, value in status.items():
            if isinstance(value, dict):
                print(f"{key}:")
                for sub_key, sub_value in value.items():
                    print(f"  {sub_key}: {sub_value}")
            else:
                print(f"{key}: {value}")
        
        return
    
    # æ‰§è¡Œé‡å»º
    result = startup_vector_rebuild(
        notes_directory=args.notes_dir,
        force_full_rebuild=args.force,
        auto_mode=args.auto
    )
    
    if result["success"]:
        print("\nğŸ‰ å‘é‡ç´¢å¼•é‡å»ºæˆåŠŸï¼")
        
        if "scan_result" in result:
            scan = result["scan_result"]
            print(f"ğŸ“Š æ‰«æç»“æœ:")
            print(f"   æ–°å¢: {len(scan['added'])} ä¸ªæ–‡ä»¶")
            print(f"   ä¿®æ”¹: {len(scan['modified'])} ä¸ªæ–‡ä»¶")  
            print(f"   åˆ é™¤: {len(scan['deleted'])} ä¸ªæ–‡ä»¶")
            print(f"   æœªå˜åŒ–: {len(scan['unchanged'])} ä¸ªæ–‡ä»¶")
        
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        print(f"   æ€»å‘é‡æ•°: {result.get('total_vectors', 0)}")
        print(f"   å‘é‡ç»´åº¦: {result.get('vector_dimension', 0)}")
        print(f"   è€—æ—¶: {result.get('duration_seconds', 0)} ç§’")
        
    else:
        print(f"\nâŒ å‘é‡ç´¢å¼•é‡å»ºå¤±è´¥: {result.get('error', 'Unknown error')}")
        sys.exit(1)


if __name__ == "__main__":
    main()
