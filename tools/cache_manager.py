#!/usr/bin/env python3
"""
æ–‡æ¡£ç¼“å­˜ç®¡ç†å·¥å…·
æä¾›ç¼“å­˜æŸ¥çœ‹ã€æ¸…ç†å’Œç®¡ç†åŠŸèƒ½
"""

import json
import os
from pathlib import Path
from datetime import datetime
from text_analyzer import ChineseTextAnalyzer


def main():
    """ç¼“å­˜ç®¡ç†ä¸»ç•Œé¢"""
    
    print("=" * 50)
    print("ğŸ“¦ æ–‡æ¡£ç¼“å­˜ç®¡ç†å·¥å…·")
    print("=" * 50)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = ChineseTextAnalyzer(
        model_name="quentinz/bge-large-zh-v1.5",
        use_ollama=True,
        collection_name="smart_notes"
    )
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ“Š æŸ¥çœ‹ç¼“å­˜çŠ¶æ€")
        print("2. ğŸ—‘ï¸  æ¸…ç©ºç¼“å­˜")
        print("3. ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ–‡æ¡£")
        print("4. ğŸ“ å¤„ç†æ–°æ–‡æ¡£ï¼ˆæ™ºèƒ½ç¼“å­˜ï¼‰")
        print("5. ğŸšª é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-5): ").strip()
        
        if choice == "1":
            show_cache_status(analyzer)
        elif choice == "2":
            clear_cache(analyzer)
        elif choice == "3":
            force_refresh(analyzer)
        elif choice == "4":
            smart_process(analyzer)
        elif choice == "5":
            print("ğŸ‘‹ å†è§ï¼")
            break
        else:
            print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")


def show_cache_status(analyzer):
    """æ˜¾ç¤ºç¼“å­˜çŠ¶æ€"""
    print("\nğŸ“Š ç¼“å­˜çŠ¶æ€è¯¦æƒ…:")
    print("-" * 40)
    
    cache_info = analyzer.get_cache_info()
    
    print(f"ç¼“å­˜æ–‡ä»¶ä½ç½®: {cache_info['cache_file_path']}")
    print(f"ç¼“å­˜æ–‡ä»¶å­˜åœ¨: {'âœ…' if cache_info['cache_exists'] else 'âŒ'}")
    print(f"å·²ç¼“å­˜æ–‡æ¡£æ•°é‡: {cache_info['total_cached_files']}")
    
    if cache_info['files']:
        print("\nğŸ“‹ æ–‡æ¡£ç¼“å­˜è¯¦æƒ…:")
        for filename, info in cache_info['files'].items():
            processed_time = info['last_processed'][:19].replace('T', ' ')
            print(f"  ğŸ“„ {filename}")
            print(f"     å—æ•°: {info['chunk_count']}")
            print(f"     å¤„ç†æ—¶é—´: {processed_time}")
            print(f"     é›†åˆ: {info['collection']}")
            print()
    else:
        print("ğŸ“ æš‚æ— ç¼“å­˜æ–‡æ¡£")


def clear_cache(analyzer):
    """æ¸…ç©ºç¼“å­˜"""
    print("\nğŸ—‘ï¸ æ¸…ç©ºç¼“å­˜")
    confirm = input("ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰æ–‡æ¡£ç¼“å­˜å—ï¼Ÿ(y/N): ").strip().lower()
    
    if confirm == 'y':
        analyzer.clear_cache()
        print("âœ… ç¼“å­˜å·²æ¸…ç©º")
    else:
        print("âŒ æ“ä½œå·²å–æ¶ˆ")


def force_refresh(analyzer):
    """å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ–‡æ¡£"""
    print("\nğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼")
    print("è¿™å°†é‡æ–°å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼Œå¿½ç•¥ç¼“å­˜...")
    
    confirm = input("ç¡®å®šè¦å¼ºåˆ¶åˆ·æ–°å—ï¼Ÿ(y/N): ").strip().lower()
    
    if confirm == 'y':
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
        notes_dir = os.path.join(os.path.dirname(__file__), "notes")
        current_dir = notes_dir if os.path.exists(notes_dir) else "."
        print("å¼€å§‹å¼ºåˆ¶åˆ·æ–°...")
        
        success = analyzer.process_directory(current_dir, force_refresh=True)
        
        if success:
            print("âœ… å¼ºåˆ¶åˆ·æ–°å®Œæˆï¼")
            # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡
            stats = analyzer.get_collection_stats()
            print(f"ğŸ“Š é›†åˆç»Ÿè®¡: æ€»è®¡ {stats['total_points']} ä¸ªå‘é‡")
        else:
            print("âŒ å¼ºåˆ¶åˆ·æ–°å¤±è´¥")
    else:
        print("âŒ æ“ä½œå·²å–æ¶ˆ")


def smart_process(analyzer):
    """æ™ºèƒ½å¤„ç†æ–‡æ¡£"""
    print("\nğŸ“ æ™ºèƒ½æ–‡æ¡£å¤„ç†")
    print("ç³»ç»Ÿå°†æ£€æŸ¥æ–‡æ¡£å˜åŒ–ï¼Œåªå¤„ç†ä¿®æ”¹è¿‡çš„æ–‡ä»¶...")
    
    # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    notes_dir = "./notes"
    if not os.path.exists(notes_dir):
        notes_dir = "."
    current_dir = notes_dir
    
    # æ˜¾ç¤ºå¤„ç†å‰çš„ç¼“å­˜çŠ¶æ€
    cache_info = analyzer.get_cache_info()
    print(f"å¤„ç†å‰: {cache_info['total_cached_files']} ä¸ªæ–‡æ¡£å·²ç¼“å­˜")
    
    success = analyzer.process_directory(current_dir, force_refresh=False)
    
    if success:
        print("âœ… æ™ºèƒ½å¤„ç†å®Œæˆï¼")
        
        # æ˜¾ç¤ºå¤„ç†åçš„çŠ¶æ€
        updated_cache_info = analyzer.get_cache_info()
        print(f"å¤„ç†å: {updated_cache_info['total_cached_files']} ä¸ªæ–‡æ¡£å·²ç¼“å­˜")
        
        stats = analyzer.get_collection_stats()
        print(f"ğŸ“Š é›†åˆç»Ÿè®¡: æ€»è®¡ {stats['total_points']} ä¸ªå‘é‡")
    else:
        print("âŒ æ™ºèƒ½å¤„ç†å¤±è´¥")


if __name__ == "__main__":
    main()
