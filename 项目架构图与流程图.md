# 「知行」 - 项目架构图与流程图

## 🎯 简要说明

「知行」是一个本地化读书笔记智能助手，旨在为用户提供高效、直观、便捷的个人知识本地管理。

### 🌟 核心功能

- **📚 智能文档处理**: 自动扫描、分析和索引本地文档，支持多种文本格式
- **🔍 混合检索机制**: 结合向量语义检索和关键词精确匹配，提供更准确的搜索结果
- **💬 流式问答体验**: 基于RAG（Retrieval-Augmented Generation）架构的智能文档问答系统，支持上下文理解和推理
- **🏠 本地化部署**: 完全基于本地模型运行，保护数据隐私，无需依赖外部API
- **🔄 增量更新机制**: 智能检测文档变化，只处理新增和修改的内容，提高处理效率
- **🎨 现代化界面**: 响应式Web界面，支持多种交互模式，提供良好的用户体验

### 🚀 技术亮点

- 采用BGE中文嵌入模型进行高质量的语义向量化
- 集成Qdrant向量数据库和SQLite关键词索引的双重检索
- 基于Ollama的本地大语言模型服务（qwen3:14b）
- 支持Server-Sent Events的实时流式响应

## 📊 项目整体架构图

```mermaid
graph TB
    %% 用户层
    subgraph "🎯 用户交互层"
        UI[🌐 Web UI<br/>Bootstrap + JavaScript<br/>响应式界面]
        CLI[💻 命令行接口<br/>多种启动模式<br/>演示工具]
        API[🔌 REST API<br/>流式问答<br/>状态监控]
    end
    
    %% 应用层
    subgraph "🚀 应用服务层"
        APP[📱 统一应用入口<br/>smart_notes_app.py<br/>6种启动模式]
        FLASK[🌐 Flask Web服务<br/>模板渲染<br/>会话管理]
        ROUTE[🔀 路由控制<br/>API端点<br/>错误处理]
    end
    
    %% 核心业务层
    subgraph "🧠 核心业务层"
        QA[❓ 问答系统<br/>QuestionAnswering<br/>上下文检索]
        ANALYZER[🔍 文本分析器<br/>ChineseTextAnalyzer<br/>向量嵌入]
        KEYWORD[🔎 关键词处理<br/>KeywordProcessor<br/>语义搜索]
        STARTUP[⚡ 启动管理<br/>VectorIndexManager<br/>自动重建]
    end
    
    %% AI模型层
    subgraph "🤖 AI模型层"
        EMBED[📊 嵌入模型<br/>bge-large-zh-v1.5<br/>向量化文本]
        LLM[🧙 大语言模型<br/>qwen3:14b<br/>问答生成]
        OLLAMA[🔥 Ollama服务<br/>本地模型服务<br/>API接口]
    end
    
    %% 存储层
    subgraph "💾 数据存储层"
        QDRANT[(🗄️ Qdrant向量库<br/>smart_notes集合<br/>语义检索)]
        SQLITE[(📋 SQLite数据库<br/>keyword_search.db<br/>关键词索引)]
        FILES[(📁 文件系统<br/>notes/目录<br/>文档缓存)]
        CACHE[(⚡ 缓存系统<br/>document_cache.json<br/>状态管理)]
    end
    
    %% 基础设施层
    subgraph "🏗️ 基础设施层"
        DOCKER[🐳 Docker容器化<br/>服务编排<br/>依赖管理]
        CONFIG[⚙️ 配置管理<br/>环境变量<br/>.env配置]
        LOG[📊 日志系统<br/>结构化日志<br/>错误追踪]
    end
    
    %% 连接关系
    UI --> APP
    CLI --> APP
    API --> FLASK
    
    APP --> FLASK
    FLASK --> ROUTE
    ROUTE --> QA
    ROUTE --> ANALYZER
    
    QA --> ANALYZER
    QA --> KEYWORD
    ANALYZER --> STARTUP
    KEYWORD --> SQLITE
    
    ANALYZER --> EMBED
    QA --> LLM
    EMBED --> OLLAMA
    LLM --> OLLAMA
    
    ANALYZER --> QDRANT
    STARTUP --> QDRANT
    STARTUP --> FILES
    ANALYZER --> CACHE
    
    DOCKER --> QDRANT
    DOCKER --> OLLAMA
    CONFIG --> APP
    LOG --> APP
    
    %% 样式
    classDef userLayer fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef appLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef coreLayer fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef aiLayer fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef storageLayer fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef infraLayer fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    
    class UI,CLI,API userLayer
    class APP,FLASK,ROUTE appLayer
    class QA,ANALYZER,KEYWORD,STARTUP coreLayer
    class EMBED,LLM,OLLAMA aiLayer
    class QDRANT,SQLITE,FILES,CACHE storageLayer
    class DOCKER,CONFIG,LOG infraLayer
```

## 🔄 核心功能实现流程图

### 1. 系统初始化流程

```mermaid
sequenceDiagram
    participant U as 用户
    participant A as smart_notes_app.py
    participant S as startup.py
    participant T as text_analyzer.py
    participant K as keyword_processor.py
    participant Q as Qdrant
    participant O as Ollama
    participant F as 文件系统
    
    U->>A: 启动应用 (web模式)
    A->>A: 解析命令行参数
    A->>S: 调用自动向量重建
    
    Note over S,F: 步骤1: 向量重建
    S->>F: 扫描notes目录
    F-->>S: 返回文件列表
    S->>S: 检查文件变化
    S->>T: 初始化文本分析器
    T->>O: 连接Ollama嵌入模型
    O-->>T: 模型就绪
    T->>Q: 连接Qdrant向量库
    Q-->>T: 连接成功
    S->>T: 处理变更文件
    T->>T: 文本分块和向量化
    T->>Q: 存储向量数据
    Q-->>S: 向量重建完成
    
    Note over A,K: 步骤2: 关键词索引
    A->>K: 初始化关键词系统
    K->>F: 扫描文档文件
    K->>K: 分词和关键词提取
    K->>K: 存储到SQLite
    K-->>A: 关键词索引完成
    
    Note over A,T: 步骤3: 文本分析器
    A->>T: 重新初始化分析器
    T->>O: 验证嵌入模型
    T->>Q: 验证向量库状态
    Q-->>T: 返回统计信息
    T-->>A: 分析器就绪
    
    Note over A,O: 步骤4: 问答系统
    A->>T: 初始化QA系统
    T->>O: 连接推理模型(qwen3:14b)
    O-->>T: 模型加载完成
    T-->>A: 问答系统就绪
    
    A->>A: 启动Flask服务
    A-->>U: 系统初始化完成
```

### 2. 智能问答流程

```mermaid
sequenceDiagram
    participant U as 用户
    participant W as Web界面
    participant A as Flask应用
    participant Q as QA系统
    participant K as 关键词系统
    participant V as 向量检索
    participant L as LLM
    participant D as 数据库
    
    U->>W: 输入问题
    W->>A: POST /api/ask_stream
    A->>A: 验证问答系统状态
    A->>Q: 开始问答流程
    
    Note over Q,K: 步骤1: 关键词提取
    Q->>Q: 分析问题文本
    Q->>K: 提取关键词
    K-->>Q: 返回关键词列表
    Q-->>A: 流式返回: 关键词提取完成
    A-->>W: SSE: 显示关键词
    
    Note over Q,V: 步骤2: 向量检索
    Q->>V: 使用关键词检索
    V->>V: 向量化查询
    V->>D: 查询Qdrant
    D-->>V: 返回相似文档
    V-->>Q: 返回上下文结果
    Q-->>A: 流式返回: 文档检索完成
    A-->>W: SSE: 显示检索到的文档
    
    Note over Q,L: 步骤3: 答案生成
    Q->>L: 构建提示词+上下文
    L->>L: 生成回答
    L-->>Q: 流式返回答案片段
    Q-->>A: 流式返回: 答案片段
    A-->>W: SSE: 实时显示答案
    
    Note over A,W: 步骤4: 完成和展示
    Q->>Q: 计算置信度
    Q-->>A: 返回完整结果
    A-->>W: SSE: 添加引用来源
    A-->>W: SSE: 显示置信度
    W-->>U: 展示完整回答
```

### 3. 文档处理流程

```mermaid
flowchart TD
    START([开始文档处理]) --> SCAN[📂 扫描notes目录]
    SCAN --> CHECK{检查文件变化}
    
    CHECK -->|有新增/修改| PROCESS[📝 处理文档]
    CHECK -->|无变化| SKIP[⏭️ 跳过处理]
    
    PROCESS --> LOAD[📖 加载文档内容]
    LOAD --> META[🏷️ 提取元数据]
    META --> CHUNK[✂️ 语义分块]
    
    CHUNK --> EMBED[🔢 向量嵌入]
    EMBED --> STORE[💾 存储向量]
    STORE --> KEYWORD[🔤 关键词提取]
    KEYWORD --> INDEX[📚 建立索引]
    
    INDEX --> CACHE[⚡ 更新缓存]
    CACHE --> UPDATE[📊 更新状态]
    UPDATE --> END([处理完成])
    
    SKIP --> END
    
    %% 并行处理
    KEYWORD --> JIEBA[🔪 jieba分词]
    JIEBA --> FILTER[🚫 停用词过滤]
    FILTER --> SQLITE[💽 存储到SQLite]
    SQLITE --> INDEX
    
    %% 错误处理
    LOAD -->|失败| ERROR[❌ 错误处理]
    EMBED -->|失败| ERROR
    STORE -->|失败| ERROR
    ERROR --> LOG[📋 记录日志]
    LOG --> CONTINUE[➡️ 继续下一个]
    CONTINUE --> END
    
    %% 样式
    classDef process fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef decision fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef storage fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef error fill:#ffebee,stroke:#d32f2f,stroke-width:2px
    
    class SCAN,LOAD,CHUNK,EMBED,KEYWORD,JIEBA,FILTER process
    class CHECK decision
    class STORE,INDEX,SQLITE,CACHE,UPDATE storage
    class ERROR,LOG error
```

## 🏗️ 技术栈依赖关系

```mermaid
graph LR
    subgraph "🐍 Python生态"
        FLASK[Flask 2.3+<br/>Web框架]
        LANGCHAIN[LangChain 0.3+<br/>文档处理]
        JIEBA[jieba 0.42+<br/>中文分词]
        NUMPY[NumPy 2.3+<br/>数值计算]
        SKLEARN[scikit-learn 1.7+<br/>机器学习]
    end
    
    subgraph "🤖 AI模型"
        BGE[bge-large-zh-v1.5<br/>中文嵌入模型<br/>1024维向量]
        QWEN[qwen3:14b<br/>中文大语言模型<br/>问答生成]
        SENTENCE[SentenceTransformers<br/>嵌入模型框架]
    end
    
    subgraph "🗄️ 数据存储"
        QDRANT_DB[Qdrant<br/>向量数据库<br/>语义检索]
        SQLITE_DB[SQLite<br/>关键词索引<br/>全文检索]
        JSON_CACHE[JSON缓存<br/>文档元数据<br/>状态管理]
    end
    
    subgraph "🔧 服务依赖"
        OLLAMA_SVC[Ollama服务<br/>localhost:11434<br/>本地模型API]
        QDRANT_SVC[Qdrant服务<br/>localhost:6333<br/>向量数据库]
        DOCKER_SVC[Docker<br/>容器化部署<br/>服务编排]
    end
    
    subgraph "🌐 前端技术"
        BOOTSTRAP[Bootstrap 5.1<br/>响应式UI]
        JAVASCRIPT[原生JavaScript<br/>实时交互]
        SSE[Server-Sent Events<br/>流式数据]
        MARKDOWN[Marked.js<br/>Markdown渲染]
        HIGHLIGHT[highlight.js<br/>代码高亮]
    end
    
    %% 依赖关系
    FLASK --> LANGCHAIN
    FLASK --> JIEBA
    LANGCHAIN --> SENTENCE
    SENTENCE --> BGE
    
    OLLAMA_SVC --> BGE
    OLLAMA_SVC --> QWEN
    
    QDRANT_SVC --> QDRANT_DB
    DOCKER_SVC --> OLLAMA_SVC
    DOCKER_SVC --> QDRANT_SVC
    
    FLASK --> SSE
    JAVASCRIPT --> BOOTSTRAP
    JAVASCRIPT --> MARKDOWN
    JAVASCRIPT --> HIGHLIGHT
    
    %% 样式
    classDef python fill:#3776ab,color:white,stroke:#3776ab,stroke-width:2px
    classDef ai fill:#ff6b35,color:white,stroke:#ff6b35,stroke-width:2px
    classDef storage fill:#00d4aa,color:white,stroke:#00d4aa,stroke-width:2px
    classDef service fill:#f39c12,color:white,stroke:#f39c12,stroke-width:2px
    classDef frontend fill:#61dafb,color:black,stroke:#61dafb,stroke-width:2px
    
    class FLASK,LANGCHAIN,JIEBA,NUMPY,SKLEARN python
    class BGE,QWEN,SENTENCE ai
    class QDRANT_DB,SQLITE_DB,JSON_CACHE storage
    class OLLAMA_SVC,QDRANT_SVC,DOCKER_SVC service
    class BOOTSTRAP,JAVASCRIPT,SSE,MARKDOWN,HIGHLIGHT frontend
```

## 📊 数据流转关系

```mermaid
flowchart TD
    %% 输入数据源
    DOC[📁 notes文档] --> LOADER[📖 文档加载器]
    USER[👤 用户问题] --> PROCESSOR[🔍 问题处理器]
    
    %% 文档处理流程
    LOADER --> CHUNKER[✂️ 语义分块器]
    CHUNKER -->|80%| EMBEDDER[🔢 向量嵌入器]
    CHUNKER -->|20%| KEYWORDS[🔤 关键词提取器]
    
    %% 存储系统
    EMBEDDER --> QDRANT[(🗄️ Qdrant向量库)]
    KEYWORDS --> SQLITE[(📋 SQLite索引)]
    
    %% 问答流程
    PROCESSOR -->|语义检索| VSEARCH[🔍 向量检索]
    PROCESSOR -->|关键词检索| KSEARCH[🔍 关键词检索]
    
    QDRANT --> VSEARCH
    SQLITE --> KSEARCH
    
    VSEARCH --> CONTEXT[📚 上下文聚合器]
    KSEARCH --> CONTEXT
    
    %% 答案生成
    CONTEXT --> LLM[🤖 大语言模型]
    LLM --> ANSWER[💬 智能回答]
    
    %% 样式
    classDef input fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef process fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef storage fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef search fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef output fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class DOC,USER input
    class LOADER,CHUNKER,EMBEDDER,KEYWORDS,PROCESSOR process
    class QDRANT,SQLITE storage
    class VSEARCH,KSEARCH,CONTEXT search
    class LLM,ANSWER output
```

## 🔄 系统生命周期

```mermaid
stateDiagram-v2
    [*] --> 启动检查
    启动检查 --> 环境验证 : 检查依赖服务
    环境验证 --> 初始化失败 : Ollama/Qdrant不可用
    环境验证 --> 数据初始化 : 服务正常
    
    数据初始化 --> 向量重建 : 检测文档变化
    向量重建 --> 关键词索引 : 向量重建完成
    关键词索引 --> 模型加载 : 索引构建完成
    模型加载 --> 系统就绪 : 所有组件就绪
    
    系统就绪 --> 问答服务 : 用户提问
    问答服务 --> 检索阶段 : 解析问题
    检索阶段 --> 生成阶段 : 获取上下文
    生成阶段 --> 系统就绪 : 返回答案
    
    系统就绪 --> 文档更新 : 新增/修改文档
    文档更新 --> 增量重建 : 处理变化
    增量重建 --> 系统就绪 : 更新完成
    
    系统就绪 --> 优雅关闭 : 用户停止
    初始化失败 --> [*] : 程序退出
    优雅关闭 --> [*] : 清理资源
    
    note right of 向量重建 : 智能增量更新<br/>仅处理变更文件
    note right of 问答服务 : 流式响应<br/>实时反馈
    note right of 模型加载 : 本地模型<br/>无网络依赖
```

## 📝 项目特色功能

### 🎯 核心优势

1. **🔄 智能增量更新**
   - 基于文件哈希的变化检测
   - 仅处理新增和修改的文档
   - 自动维护向量索引一致性

2. **🚀 流式问答体验**
   - Server-Sent Events 实时推送
   - 分阶段显示处理过程
   - 打字机效果的答案展示

3. **🧠 双重检索机制**
   - 向量语义检索(Qdrant)
   - 关键词精确检索(SQLite)
   - 混合检索提升准确性

4. **🏠 本地化部署**
   - Ollama本地模型服务
   - Docker容器化部署
   - 无需云端API密钥

5. **🎨 现代化界面**
   - 响应式Web设计
   - 实时状态监控
   - 多种交互模式

### 🔧 技术创新

- **语义分块**: 基于句子相似度的智能分块，避免文本割裂
- **中文优化**: 针对中文文本的分词和向量化优化
- **状态管理**: 完整的系统状态跟踪和错误恢复
- **模块化设计**: 清晰的分层架构，易于扩展和维护

这个智能问答系统通过现代化的RAG架构，结合本地化AI模型，为用户提供了一个高效、智能、易用的文档问答解决方案。
